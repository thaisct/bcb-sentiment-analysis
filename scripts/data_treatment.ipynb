{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\Thais\\\\Documents\\\\Python\\\\bcb-sentiment-analysis\")\n",
    "\n",
    "import datetime \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import BDay\n",
    "import scipy as sc\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DAILY_DATA = \".\\\\data\\\\financial data\\\\daily.xlsx\"\n",
    "MINUTES_DATA = \".\\\\data\\\\minutes\\\\copom_dates.xlsx\"\n",
    "MINUTES_SCORE = \".\\\\data\\\\minutes\\\\minutes_scores_uncased_20230423.pkl\"\n",
    "TARGET_INFLATION_DATA = \".\\\\data\\\\financial data\\\\historico_meta_inflacao.xlsx\"\n",
    "INDEPENDENT_VARIABLES = \".\\\\data\\\\output\\\\independent.xlsx\"\n",
    "INDEPENDENT_VARIABLES_ROBUST = \".\\\\data\\\\output\\\\independent_robust.xlsx\"\n",
    "INDEPENDENT_VARIABLES_ALT = \".\\\\data\\\\output\\\\independent_no_ffill.xlsx\"\n",
    "INDEPENDENT_VARIABLES_ROBUST_ALT = \".\\\\data\\\\output\\\\independent_robust_no_ffill.xlsx\"\n",
    "\n",
    "last_date = datetime.datetime(2023, 4, 11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Processing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Daily Historical Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenors_headers = [\"21D\",\"42D\",\"63D\",\"84D\",\"105D\",\"126D\",\"147D\",\"168D\",\"189D\",\"210D\",\"231D\",\"252D\",\"273D\",\"294D\",\"504D\",\"756D\",\"1260D\",\"1512D\",\"1764D\",\"2016D\",\"2268D\",\"2520D\",\"2772D\"]\n",
    "daily_vol = pd.read_excel(DAILY_DATA, sheet_name='vol', skiprows=5).set_index('Dates')\n",
    "daily_vol.columns = tenors_headers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - IPCA series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diário\n",
    "ipca_yoy_desv_centro = pd.read_excel(TARGET_INFLATION_DATA, sheet_name='ipca_yoy_ano_corrente').set_index('date')[['desvio_centro_perc']]\n",
    "ipca_yoy_desv_interv = pd.read_excel(TARGET_INFLATION_DATA, sheet_name='ipca_yoy_ano_corrente').set_index('date')[['desvio_intervalo_perc']]\n",
    "\n",
    "#Dias que saiu IPCA\n",
    "ipca_mom_desv_expect = pd.read_excel(TARGET_INFLATION_DATA, sheet_name='ipca_mom_ano_corrente').set_index('date')[['desvio_expectativa_perc']]\n",
    "\n",
    "#Diário\n",
    "ipca_hpm_desv_centro = pd.read_excel(TARGET_INFLATION_DATA, sheet_name='ipca_horizonte_PM').set_index('date')[['desvio_centro_perc']]\n",
    "ipca_hpm_desv_interv = pd.read_excel(TARGET_INFLATION_DATA, sheet_name='ipca_horizonte_PM').set_index('date')[['desvio_intervalo_perc']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - SELIC Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "selic_raw = pd.read_excel(MINUTES_DATA, sheet_name = 'Plan1').set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selic_surprise_v = selic_raw[['decision_date','selic_surprise_v']].reset_index().set_index('decision_date').drop(columns = ['date'])\n",
    "selic_frd = selic_raw[['decision_date','frd_guidance']].reset_index().set_index('decision_date').drop(columns = ['date'])\n",
    "d_inicio = pd.DataFrame(selic_raw['d_inicio'])\n",
    "d_fim = pd.DataFrame(selic_raw['d_fim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ata = pd.read_excel(MINUTES_DATA, sheet_name = 'd_ata').set_index('date')\n",
    "d_ato = pd.read_excel(MINUTES_DATA, sheet_name = 'd_ato').set_index('date')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Minutes score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_score = pd.read_pickle(MINUTES_SCORE).reset_index().set_index('date')[['score']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 - CDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_headers = [\"CO1 Comdty\",\"CL1 Comdty\",\"CRB CMDT Index\",\"VIX Index\",\"BRAZIL CDS USD SR 5Y D14 Corp\"]\n",
    "cds = pd.read_excel(DAILY_DATA, sheet_name='other_controls', skiprows=5).set_index('Dates')\n",
    "cds.columns = col_headers\n",
    "cds_s = cds[[\"BRAZIL CDS USD SR 5Y D14 Corp\"]]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Joining all in one dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime(2001, 10, 12) #data que todas as séries tem dado\n",
    "end_date = datetime.datetime(2022, 12, 13) #última ata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regenerate data resampled\n",
    "ls_df = [cds_s, minute_score, selic_frd, selic_surprise_v, ipca_mom_desv_expect,\n",
    "        ipca_yoy_desv_interv, ipca_yoy_desv_centro, ipca_hpm_desv_interv, ipca_hpm_desv_centro, d_ata, d_ato,\n",
    "        d_inicio, d_fim]\n",
    "\n",
    "new_ls_df = []\n",
    "for df in ls_df:\n",
    "    df.index.name = 'date'\n",
    "    temp = df.resample('D').ffill()\n",
    "    \n",
    "    df_filtered = temp[(temp.index >= start_date) & (temp.index <= end_date)]\n",
    "\n",
    "    new_ls_df.append(df_filtered)\n",
    "\n",
    "df_independent = pd.concat(new_ls_df, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_headers = ['CDS', 'minutes_score', 'frd_guidance','selic_surprise_v', 'desvio_expectativa_perc',\n",
    "                           'desvio_intervalo_perc','desvio_centro_perc', 'desvio_intervalo_hpm_perc', \n",
    "                           'desvio_centro_hpm_perc', 'd_ata', 'd_ato', 'd_inicio', 'd_fim']\n",
    "\n",
    "df_independent = pd.read_excel(INDEPENDENT_VARIABLES_ALT).set_index('date')\n",
    "df_independent.columns = column_headers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vol = daily_vol.resample('D').ffill() \n",
    "df_dependent = df_vol[(df_vol.index >= start_date) & (df_vol.index <= end_date)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Regressions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Sem controles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.0 - vol_di = NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = []\n",
    "\n",
    "for tenor in tenors_headers:\n",
    "\n",
    "    # define column of tenors\n",
    "    lst_tenor = [tenor]\n",
    "    rep_lst_tenors = np.repeat(lst_tenor, [1+1], axis=0)\n",
    "\n",
    "    # define your dependent variable\n",
    "    y = df_dependent[tenor]\n",
    "\n",
    "    # define your independent variables\n",
    "    x1 = df_independent['minutes_score']\n",
    "\n",
    "    # create a matrix of your independent variables\n",
    "    X = sm.add_constant(pd.concat([x1], axis=1))\n",
    "\n",
    "    # create the OLS model and fit it to your data\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    # obtain a summary table in a structured format\n",
    "    summary_table = model.summary2()\n",
    "\n",
    "    # extract the p-values ans SD columns from the table\n",
    "    p_values = summary_table.tables[1]['P>|t|']\n",
    "    sd = summary_table.tables[1]['Std.Err.']\n",
    "    beta = summary_table.tables[1]['Coef.']\n",
    "\n",
    "    # create a pandas dataframe to store the p-values\n",
    "    p_values_df = pd.DataFrame({'variable': p_values.index, 'tenor': rep_lst_tenors, 'beta':beta.values, \n",
    "                                'sd':sd.values, 'p-value': p_values.values})\n",
    "    ls_df.append(p_values_df)\n",
    "\n",
    "df_values_310 = pd.concat(ls_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 - vol_di = NLP + D_decisão + D_ata + Selic Surprise value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = []\n",
    "\n",
    "for tenor in tenors_headers:\n",
    "\n",
    "    # define column of tenors\n",
    "    lst_tenor = [tenor]\n",
    "    rep_lst_tenors = np.repeat(lst_tenor, [4+1], axis=0)\n",
    "\n",
    "    # define your dependent variable\n",
    "    y = df_dependent[tenor]\n",
    "\n",
    "    # define your independent variables\n",
    "    x1 = df_independent['minutes_score']\n",
    "    x2 = df_independent['selic_surprise_v']\n",
    "    x3 = df_independent['d_ato']\n",
    "    x4 = df_independent['d_ata']\n",
    "\n",
    "    # create a matrix of your independent variables\n",
    "    X = sm.add_constant(pd.concat([x1, x2, x3, x4], axis=1))\n",
    "\n",
    "    # create the OLS model and fit it to your data\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    # obtain a summary table in a structured format\n",
    "    summary_table = model.summary2()\n",
    "\n",
    "    # extract the p-values ans SD columns from the table\n",
    "    p_values = summary_table.tables[1]['P>|t|']\n",
    "    sd = summary_table.tables[1]['Std.Err.']\n",
    "    beta = summary_table.tables[1]['Coef.']\n",
    "\n",
    "    # create a pandas dataframe to store the p-values\n",
    "    p_values_df = pd.DataFrame({'variable': p_values.index, 'tenor': rep_lst_tenors, 'beta':beta.values, \n",
    "                                'sd':sd.values, 'p-value': p_values.values})\n",
    "    ls_df.append(p_values_df)\n",
    "\n",
    "df_values_311 = pd.concat(ls_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 - vol_di = NLP + D_decisão + Selic Surprise value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = []\n",
    "\n",
    "for tenor in tenors_headers:\n",
    "\n",
    "    # define column of tenors\n",
    "    lst_tenor = [tenor]\n",
    "    rep_lst_tenors = np.repeat(lst_tenor, [3+1], axis=0)\n",
    "\n",
    "    # define your dependent variable\n",
    "    y = df_dependent[tenor]\n",
    "\n",
    "    # define your independent variables\n",
    "    x1 = df_independent['minutes_score']\n",
    "    x2 = df_independent['selic_surprise_v']\n",
    "    x3 = df_independent['d_ato']\n",
    "\n",
    "    # create a matrix of your independent variables\n",
    "    X = sm.add_constant(pd.concat([x1, x2, x3], axis=1))\n",
    "\n",
    "    # create the OLS model and fit it to your data\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    # obtain a summary table in a structured format\n",
    "    summary_table = model.summary2()\n",
    "\n",
    "    # extract the p-values ans SD columns from the table\n",
    "    p_values = summary_table.tables[1]['P>|t|']\n",
    "    sd = summary_table.tables[1]['Std.Err.']\n",
    "    beta = summary_table.tables[1]['Coef.']\n",
    "\n",
    "    # create a pandas dataframe to store the p-values\n",
    "    p_values_df = pd.DataFrame({'variable': p_values.index, 'tenor': rep_lst_tenors, 'beta':beta.values, \n",
    "                                'sd':sd.values, 'p-value': p_values.values})\n",
    "    ls_df.append(p_values_df)\n",
    "\n",
    "df_values_312 = pd.concat(ls_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 - vol_di = NLP + D_ata + Selic Surprise value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = []\n",
    "\n",
    "for tenor in tenors_headers:\n",
    "\n",
    "    # define column of tenors\n",
    "    lst_tenor = [tenor]\n",
    "    rep_lst_tenors = np.repeat(lst_tenor, [3+1], axis=0)\n",
    "\n",
    "    # define your dependent variable\n",
    "    y = df_dependent[tenor]\n",
    "\n",
    "    # define your independent variables\n",
    "    x1 = df_independent['minutes_score']\n",
    "    x2 = df_independent['selic_surprise_v']\n",
    "    x3 = df_independent['d_ata']\n",
    "\n",
    "    # create a matrix of your independent variables\n",
    "    X = sm.add_constant(pd.concat([x1, x2, x3], axis=1))\n",
    "\n",
    "    # create the OLS model and fit it to your data\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    # obtain a summary table in a structured format\n",
    "    summary_table = model.summary2()\n",
    "\n",
    "    # extract the p-values ans SD columns from the table\n",
    "    p_values = summary_table.tables[1]['P>|t|']\n",
    "    sd = summary_table.tables[1]['Std.Err.']\n",
    "    beta = summary_table.tables[1]['Coef.']\n",
    "\n",
    "    # create a pandas dataframe to store the p-values\n",
    "    p_values_df = pd.DataFrame({'variable': p_values.index, 'tenor': rep_lst_tenors, 'beta':beta.values, \n",
    "                                'sd':sd.values, 'p-value': p_values.values})\n",
    "    ls_df.append(p_values_df)\n",
    "\n",
    "df_values_313 = pd.concat(ls_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Com controles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 - vol_di = NLP + D_ato + D_ata + ... + Selic Surprise valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = []\n",
    "\n",
    "for tenor in tenors_headers:\n",
    "\n",
    "    # define column of tenors\n",
    "    lst_tenor = [tenor]\n",
    "    rep_lst_tenors = np.repeat(lst_tenor, [13+1], axis=0)\n",
    "\n",
    "    # define your dependent variable\n",
    "    y = df_dependent[tenor]\n",
    "\n",
    "    # define your independent variables\n",
    "    x1 = df_independent['minutes_score']\n",
    "    x2 = df_independent['selic_surprise_v']\n",
    "    x3 = df_independent['d_ato']\n",
    "    x4 = df_independent['d_ata']\n",
    "    x5 = df_independent['frd_guidance']\n",
    "    x6 = df_independent['desvio_expectativa_perc']\n",
    "    x7 = df_independent['desvio_intervalo_perc']\n",
    "    x8 = df_independent['desvio_centro_perc']\n",
    "    x9 = df_independent['desvio_intervalo_hpm_perc']\n",
    "    x10 = df_independent['desvio_centro_hpm_perc']\n",
    "    x11 = df_independent['CDS']\n",
    "    x12 = df_independent['d_inicio']\n",
    "    x13 = df_independent['d_fim']\n",
    "\n",
    "    # create a matrix of your independent variables\n",
    "    X = sm.add_constant(pd.concat([x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13], axis=1))\n",
    "\n",
    "    # create the OLS model and fit it to your data\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    # obtain a summary table in a structured format\n",
    "    summary_table = model.summary2()\n",
    "\n",
    "    # extract the p-values ans SD columns from the table\n",
    "    p_values = summary_table.tables[1]['P>|t|']\n",
    "    sd = summary_table.tables[1]['Std.Err.']\n",
    "    beta = summary_table.tables[1]['Coef.']\n",
    "\n",
    "    # create a pandas dataframe to store the p-values\n",
    "    p_values_df = pd.DataFrame({'variable': p_values.index, 'tenor': rep_lst_tenors, 'beta':beta.values, \n",
    "                                'sd':sd.values, 'p-value': p_values.values})\n",
    "\n",
    "    ls_df.append(p_values_df)\n",
    "\n",
    "df_values_321 = pd.concat(ls_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(\"modelos_20230608_alt.xlsx\", engine=\"xlsxwriter\")\n",
    "\n",
    "# Write each dataframe to a different worksheet.\n",
    "df_values_310.to_excel(writer, sheet_name=\"df_values_310\")\n",
    "df_values_311.to_excel(writer, sheet_name=\"df_values_311\")\n",
    "df_values_312.to_excel(writer, sheet_name=\"df_values_312\")\n",
    "df_values_313.to_excel(writer, sheet_name=\"df_values_313\")\n",
    "df_values_321.to_excel(writer, sheet_name=\"df_values_321\")\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINUTES_SCORE_UNCASED = \".\\\\data\\\\minutes\\\\minutes_scores_uncased.pkl\"\n",
    "minute_score_uncased = pd.read_pickle(MINUTES_SCORE_UNCASED).reset_index().set_index('date')[['score']].resample('D').ffill()\n",
    "minute_score_uncased = minute_score_uncased[(minute_score_uncased.index >= start_date) & (minute_score_uncased.index <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regenerate data resampled\n",
    "ls_df = [cds_s, minute_score_uncased, selic_frd, selic_surprise_v, ipca_mom_desv_expect,\n",
    "        ipca_yoy_desv_interv, ipca_yoy_desv_centro, ipca_hpm_desv_interv, ipca_hpm_desv_centro, d_ata, d_ato,\n",
    "        d_inicio, d_fim]\n",
    "\n",
    "new_ls_df = []\n",
    "for df in ls_df:\n",
    "    df.index.name = 'date'\n",
    "    temp = df.resample('D').ffill()\n",
    "    \n",
    "    df_filtered = temp[(temp.index >= start_date) & (temp.index <= end_date)]\n",
    "\n",
    "    new_ls_df.append(df_filtered)\n",
    "\n",
    "df_independent = pd.concat(new_ls_df, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_headers = ['CDS', 'minutes_score', 'frd_guidance','selic_surprise_v', 'desvio_expectativa_perc',\n",
    "                           'desvio_intervalo_perc','desvio_centro_perc', 'desvio_intervalo_hpm_perc', \n",
    "                           'desvio_centro_hpm_perc', 'd_ata', 'd_ato', 'd_inicio', 'd_fim']\n",
    "\n",
    "df_independent = pd.read_excel(INDEPENDENT_VARIABLES_ROBUST_ALT).set_index('date')\n",
    "df_independent.columns = column_headers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = []\n",
    "\n",
    "for tenor in tenors_headers:\n",
    "\n",
    "    # define column of tenors\n",
    "    lst_tenor = [tenor]\n",
    "    rep_lst_tenors = np.repeat(lst_tenor, [1+1], axis=0)\n",
    "\n",
    "    # define your dependent variable\n",
    "    y = df_dependent[tenor]\n",
    "\n",
    "    # define your independent variables\n",
    "    x1 = df_independent['minutes_score']\n",
    "\n",
    "    # create a matrix of your independent variables\n",
    "    X = sm.add_constant(pd.concat([x1], axis=1))\n",
    "\n",
    "    # create the OLS model and fit it to your data\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    # obtain a summary table in a structured format\n",
    "    summary_table = model.summary2()\n",
    "\n",
    "    # extract the p-values ans SD columns from the table\n",
    "    p_values = summary_table.tables[1]['P>|t|']\n",
    "    sd = summary_table.tables[1]['Std.Err.']\n",
    "    beta = summary_table.tables[1]['Coef.']\n",
    "\n",
    "    # create a pandas dataframe to store the p-values\n",
    "    p_values_df = pd.DataFrame({'variable': p_values.index, 'tenor': rep_lst_tenors, 'beta':beta.values, \n",
    "                                'sd':sd.values, 'p-value': p_values.values})\n",
    "    ls_df.append(p_values_df)\n",
    "\n",
    "df_values_r310 = pd.concat(ls_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = []\n",
    "\n",
    "for tenor in tenors_headers:\n",
    "\n",
    "    # define column of tenors\n",
    "    lst_tenor = [tenor]\n",
    "    rep_lst_tenors = np.repeat(lst_tenor, [4+1], axis=0)\n",
    "\n",
    "    # define your dependent variable\n",
    "    y = df_dependent[tenor]\n",
    "\n",
    "    # define your independent variables\n",
    "    x1 = df_independent['minutes_score']\n",
    "    x2 = df_independent['selic_surprise_v']\n",
    "    x3 = df_independent['d_ato']\n",
    "    x4 = df_independent['d_ata']\n",
    "\n",
    "    # create a matrix of your independent variables\n",
    "    X = sm.add_constant(pd.concat([x1, x2, x3, x4], axis=1))\n",
    "\n",
    "    # create the OLS model and fit it to your data\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    # obtain a summary table in a structured format\n",
    "    summary_table = model.summary2()\n",
    "\n",
    "    # extract the p-values ans SD columns from the table\n",
    "    p_values = summary_table.tables[1]['P>|t|']\n",
    "    sd = summary_table.tables[1]['Std.Err.']\n",
    "    beta = summary_table.tables[1]['Coef.']\n",
    "\n",
    "    # create a pandas dataframe to store the p-values\n",
    "    p_values_df = pd.DataFrame({'variable': p_values.index, 'tenor': rep_lst_tenors, 'beta':beta.values, \n",
    "                                'sd':sd.values, 'p-value': p_values.values})\n",
    "    ls_df.append(p_values_df)\n",
    "\n",
    "df_values_r311 = pd.concat(ls_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = []\n",
    "\n",
    "for tenor in tenors_headers:\n",
    "\n",
    "    # define column of tenors\n",
    "    lst_tenor = [tenor]\n",
    "    rep_lst_tenors = np.repeat(lst_tenor, [3+1], axis=0)\n",
    "\n",
    "    # define your dependent variable\n",
    "    y = df_dependent[tenor]\n",
    "\n",
    "    # define your independent variables\n",
    "    x1 = df_independent['minutes_score']\n",
    "    x2 = df_independent['selic_surprise_v']\n",
    "    x3 = df_independent['d_ato']\n",
    "\n",
    "    # create a matrix of your independent variables\n",
    "    X = sm.add_constant(pd.concat([x1, x2, x3], axis=1))\n",
    "\n",
    "    # create the OLS model and fit it to your data\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    # obtain a summary table in a structured format\n",
    "    summary_table = model.summary2()\n",
    "\n",
    "    # extract the p-values ans SD columns from the table\n",
    "    p_values = summary_table.tables[1]['P>|t|']\n",
    "    sd = summary_table.tables[1]['Std.Err.']\n",
    "    beta = summary_table.tables[1]['Coef.']\n",
    "\n",
    "    # create a pandas dataframe to store the p-values\n",
    "    p_values_df = pd.DataFrame({'variable': p_values.index, 'tenor': rep_lst_tenors, 'beta':beta.values, \n",
    "                                'sd':sd.values, 'p-value': p_values.values})\n",
    "    ls_df.append(p_values_df)\n",
    "\n",
    "df_values_r312 = pd.concat(ls_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = []\n",
    "\n",
    "for tenor in tenors_headers:\n",
    "\n",
    "    # define column of tenors\n",
    "    lst_tenor = [tenor]\n",
    "    rep_lst_tenors = np.repeat(lst_tenor, [3+1], axis=0)\n",
    "\n",
    "    # define your dependent variable\n",
    "    y = df_dependent[tenor]\n",
    "\n",
    "    # define your independent variables\n",
    "    x1 = df_independent['minutes_score']\n",
    "    x2 = df_independent['selic_surprise_v']\n",
    "    x3 = df_independent['d_ata']\n",
    "\n",
    "    # create a matrix of your independent variables\n",
    "    X = sm.add_constant(pd.concat([x1, x2, x3], axis=1))\n",
    "\n",
    "    # create the OLS model and fit it to your data\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    # obtain a summary table in a structured format\n",
    "    summary_table = model.summary2()\n",
    "\n",
    "    # extract the p-values ans SD columns from the table\n",
    "    p_values = summary_table.tables[1]['P>|t|']\n",
    "    sd = summary_table.tables[1]['Std.Err.']\n",
    "    beta = summary_table.tables[1]['Coef.']\n",
    "\n",
    "    # create a pandas dataframe to store the p-values\n",
    "    p_values_df = pd.DataFrame({'variable': p_values.index, 'tenor': rep_lst_tenors, 'beta':beta.values, \n",
    "                                'sd':sd.values, 'p-value': p_values.values})\n",
    "    ls_df.append(p_values_df)\n",
    "\n",
    "df_values_r313 = pd.concat(ls_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = []\n",
    "\n",
    "for tenor in tenors_headers:\n",
    "\n",
    "    # define column of tenors\n",
    "    lst_tenor = [tenor]\n",
    "    rep_lst_tenors = np.repeat(lst_tenor, [13+1], axis=0)\n",
    "\n",
    "    # define your dependent variable\n",
    "    y = df_dependent[tenor]\n",
    "\n",
    "    # define your independent variables\n",
    "    x1 = df_independent['minutes_score']\n",
    "    x2 = df_independent['selic_surprise_v']\n",
    "    x3 = df_independent['d_ato']\n",
    "    x4 = df_independent['d_ata']\n",
    "    x5 = df_independent['frd_guidance']\n",
    "    x6 = df_independent['desvio_expectativa_perc']\n",
    "    x7 = df_independent['desvio_intervalo_perc']\n",
    "    x8 = df_independent['desvio_centro_perc']\n",
    "    x9 = df_independent['desvio_intervalo_hpm_perc']\n",
    "    x10 = df_independent['desvio_centro_hpm_perc']\n",
    "    x11 = df_independent['CDS']\n",
    "    x12 = df_independent['d_inicio']\n",
    "    x13 = df_independent['d_fim']\n",
    "\n",
    "    # create a matrix of your independent variables\n",
    "    X = sm.add_constant(pd.concat([x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13], axis=1))\n",
    "\n",
    "    # create the OLS model and fit it to your data\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    # obtain a summary table in a structured format\n",
    "    summary_table = model.summary2()\n",
    "\n",
    "    # extract the p-values ans SD columns from the table\n",
    "    p_values = summary_table.tables[1]['P>|t|']\n",
    "    sd = summary_table.tables[1]['Std.Err.']\n",
    "    beta = summary_table.tables[1]['Coef.']\n",
    "\n",
    "    # create a pandas dataframe to store the p-values\n",
    "    p_values_df = pd.DataFrame({'variable': p_values.index, 'tenor': rep_lst_tenors, 'beta':beta.values, \n",
    "                                'sd':sd.values, 'p-value': p_values.values})\n",
    "\n",
    "    ls_df.append(p_values_df)\n",
    "\n",
    "df_values_r321 = pd.concat(ls_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(\"summary_robustness_alt.xlsx\", engine=\"xlsxwriter\")\n",
    "\n",
    "# Write each dataframe to a different worksheet.\n",
    "df_values_r310.to_excel(writer, sheet_name=\"df_values_r310\")\n",
    "df_values_r311.to_excel(writer, sheet_name=\"df_values_r311\")\n",
    "df_values_r312.to_excel(writer, sheet_name=\"df_values_r312\")\n",
    "df_values_r313.to_excel(writer, sheet_name=\"df_values_r313\")\n",
    "df_values_r321.to_excel(writer, sheet_name=\"df_values_r321\")\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazer entre minutes_score e SELIC + EXPECTATIVA INFLAÇÃO 12m (no dia da decisão) + EXPECTATIVA GDP anual (no dia da decisão) + FX expectativa de final de ano (no dia da decisão)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_independent.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_corr = df_independent[['FCI','minutes_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.matshow(df_corr.corr())\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
